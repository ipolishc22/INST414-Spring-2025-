{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Model 1\n",
      "Accuracy: 0.0393\n",
      "Drama - Precision:0.5000, Recall:0.0440, F1:0.0809\n",
      "Comedy - Precision:0.3043, Recall:0.0365, F1:0.0651\n",
      "Horror - Precision:0.1446, Recall:0.0380, F1:0.0602\n"
     ]
    }
   ],
   "source": [
    "model_pred_df = pd.read_csv('prediction_model_01.csv')\n",
    "\n",
    "genres_of_interest = ['Drama', 'Comedy', 'Horror']\n",
    "\n",
    "genre_true_counts = {genre:0 for genre in genres_of_interest}\n",
    "genre_tp_counts = {genre:0 for genre in genres_of_interest}\n",
    "genre_fp_counts = {genre:0 for genre in genres_of_interest}\n",
    "\n",
    "for idx, row in model_pred_df.iterrows():\n",
    "    actual_genres = row['actual genres']\n",
    "\n",
    "    for true_g in genres_of_interest:\n",
    "        if true_g in actual_genres:\n",
    "            genre_true_counts[true_g] += 1\n",
    "    pred_g = row['predicted']\n",
    "    correct = row['correct?']\n",
    "\n",
    "    for genre in genres_of_interest:\n",
    "        if pred_g == genre:\n",
    "            if  correct == 1:\n",
    "                genre_tp_counts[genre] += 1\n",
    "            else:\n",
    "                genre_fp_counts[genre] += 1\n",
    "\n",
    "\n",
    "precision = {}\n",
    "recall = {}\n",
    "f1_score = {}\n",
    "accuracy = 0\n",
    "correct_predictions = 0\n",
    "\n",
    "for genre in genres_of_interest:\n",
    "    tp = genre_tp_counts[genre]\n",
    "    fp = genre_fp_counts[genre]\n",
    "    fn = genre_true_counts[genre] - tp\n",
    "\n",
    "    precision[genre] = tp/(tp+fp) if (tp+fp)>0 else 0\n",
    "    recall[genre] = tp/(tp+fn) if (tp+fn)>0 else 0\n",
    "    f1_score[genre] = 2 *(precision[genre]*recall[genre]) / (precision[genre]+recall[genre]) if (precision[genre]+recall[genre])>0 else 0\n",
    "\n",
    "    correct_predictions += tp\n",
    "    accuracy = correct_predictions/len(model_pred_df)\n",
    "\n",
    "print(\"For Model 1\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "for genre in genres_of_interest:\n",
    "    print(f\"{genre} - Precision:{precision[genre]:.4f}, Recall:{recall[genre]:.4f}, F1:{f1_score[genre]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Model 2\n",
      "Accuracy: 0.4727\n",
      "Drama - Precision:0.6219, Recall:0.6681, F1:0.6442\n",
      "Comedy - Precision:0.5273, Recall:0.2799, F1:0.3657\n",
      "Horror - Precision:0.5988, Recall:0.3180, F1:0.4154\n"
     ]
    }
   ],
   "source": [
    "model_pred_df = pd.read_csv('prediction_model_02.csv')\n",
    "\n",
    "genres_of_interest = ['Drama', 'Comedy', 'Horror']\n",
    "\n",
    "genre_true_counts = {genre:0 for genre in genres_of_interest}\n",
    "genre_tp_counts = {genre:0 for genre in genres_of_interest}\n",
    "genre_fp_counts = {genre:0 for genre in genres_of_interest}\n",
    "\n",
    "for idx, row in model_pred_df.iterrows():\n",
    "    actual_genres = row['actual genres']\n",
    "\n",
    "    for true_g in genres_of_interest:\n",
    "        if true_g in actual_genres:\n",
    "            genre_true_counts[true_g] += 1\n",
    "    pred_g = row['predicted']\n",
    "    correct = row['correct?']\n",
    "\n",
    "    for genre in genres_of_interest:\n",
    "        if pred_g == genre:\n",
    "            if  correct == 1:\n",
    "                genre_tp_counts[genre] += 1\n",
    "            else:\n",
    "                genre_fp_counts[genre] += 1\n",
    "\n",
    "\n",
    "precision = {}\n",
    "recall = {}\n",
    "f1_score = {}\n",
    "accuracy = 0\n",
    "correct_predictions = 0\n",
    "\n",
    "for genre in genres_of_interest:\n",
    "    tp = genre_tp_counts[genre]\n",
    "    fp = genre_fp_counts[genre]\n",
    "    fn = genre_true_counts[genre] - tp\n",
    "\n",
    "    precision[genre] = tp/(tp+fp) if (tp+fp)>0 else 0\n",
    "    recall[genre] = tp/(tp+fn) if (tp+fn)>0 else 0\n",
    "    f1_score[genre] = 2 *(precision[genre]*recall[genre]) / (precision[genre]+recall[genre]) if (precision[genre]+recall[genre])>0 else 0\n",
    "\n",
    "    correct_predictions += tp\n",
    "    accuracy = correct_predictions/len(model_pred_df)\n",
    "\n",
    "print(\"For Model 2\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "for genre in genres_of_interest:\n",
    "    print(f\"{genre} - Precision:{precision[genre]:.4f}, Recall:{recall[genre]:.4f}, F1:{f1_score[genre]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Model 3\n",
      "Accuracy: 0.4981\n",
      "Drama - Precision:0.4981, Recall:1.0000, F1:0.6650\n",
      "Comedy - Precision:0.0000, Recall:0.0000, F1:0.0000\n",
      "Horror - Precision:0.0000, Recall:0.0000, F1:0.0000\n"
     ]
    }
   ],
   "source": [
    "model_pred_df = pd.read_csv('prediction_model_03.csv')\n",
    "\n",
    "genres_of_interest = ['Drama', 'Comedy', 'Horror']\n",
    "\n",
    "genre_true_counts = {genre:0 for genre in genres_of_interest}\n",
    "genre_tp_counts = {genre:0 for genre in genres_of_interest}\n",
    "genre_fp_counts = {genre:0 for genre in genres_of_interest}\n",
    "\n",
    "for idx, row in model_pred_df.iterrows():\n",
    "    actual_genres = row['actual genres']\n",
    "\n",
    "    for true_g in genres_of_interest:\n",
    "        if true_g in actual_genres:\n",
    "            genre_true_counts[true_g] += 1\n",
    "    pred_g = row['predicted']\n",
    "    correct = row['correct?']\n",
    "\n",
    "    for genre in genres_of_interest:\n",
    "        if pred_g == genre:\n",
    "            if  correct == 1:\n",
    "                genre_tp_counts[genre] += 1\n",
    "            else:\n",
    "                genre_fp_counts[genre] += 1\n",
    "\n",
    "\n",
    "precision = {}\n",
    "recall = {}\n",
    "f1_score = {}\n",
    "accuracy = 0\n",
    "correct_predictions = 0\n",
    "\n",
    "for genre in genres_of_interest:\n",
    "    tp = genre_tp_counts[genre]\n",
    "    fp = genre_fp_counts[genre]\n",
    "    fn = genre_true_counts[genre] - tp\n",
    "\n",
    "    precision[genre] = tp/(tp+fp) if (tp+fp)>0 else 0\n",
    "    recall[genre] = tp/(tp+fn) if (tp+fn)>0 else 0\n",
    "    f1_score[genre] = 2 *(precision[genre]*recall[genre]) / (precision[genre]+recall[genre]) if (precision[genre]+recall[genre])>0 else 0\n",
    "\n",
    "    correct_predictions += tp\n",
    "    accuracy = correct_predictions/len(model_pred_df)\n",
    "\n",
    "print(\"For Model 3\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "for genre in genres_of_interest:\n",
    "    print(f\"{genre} - Precision:{precision[genre]:.4f}, Recall:{recall[genre]:.4f}, F1:{f1_score[genre]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 2 produces the best predicitons, since the average of F1 values for that model is the greatest. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
